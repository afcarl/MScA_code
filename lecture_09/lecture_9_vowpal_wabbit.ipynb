{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9: Stochastic Gradient Descent and Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to note is that this is **NOT** a regular ipython notebook.  It uses the bash kernel that you need to install from [here](https://github.com/takluyver/bash_kernel) to execute normal linux commands rather than just regular python.  You need ipython version 3 for it to work.  It's pretty sweet though--you can switch back and forth between executing linux commands and python commands by going to the \"Change kernel\" option in the \"Kernel\" menu above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be looking at a dataset of display ad click logs from online display advertising from Criteo.  It's a much larger version of a [Kaggle competition dataset](https://www.kaggle.com/c/criteo-display-ad-challenge).  The dataset is a terabyte and has records for 24 days, but we'll only be looking at a single day of data.  You can get the data [here](http://labs.criteo.com/downloads/download-terabyte-click-logs/).  There's also a nice [blog post](http://fastml.com/vowpal-wabbit-eats-big-data-from-the-criteo-competition-for-breakfast/) about using VW in the Criteo contest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how large the file is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -lh data/day_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46 GB is pretty gigantic, and clearly to large to load into my laptop's RAM.  So VW is a good option here.  Let's see how many lines (examples there are in the file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THIS WILL TAKE A LONG TIME\n",
    "wc -l data/day_0\n",
    "#195,841,983"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first two lines of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t5\t110\t\t16\t\t1\t0\t14\t7\t1\t\t306\t\t62770d79\te21f5d58\tafea442f\t945c7fcf\t38b02748\t6fcd6dcb\t3580aa21\t28808903\t46dedfa6\t2e027dc1\t0c7c4231\t95981d1f\t00c5ffb7\tbe4ee537\t8a0b74cc\t4cdc3efa\td20856aa\tb8170bba\t9512c20b\tc38e2f28\t14f65a5d\t25b1b089\td7c1fc0b\t7caf609c\t30436bfc\ted10571d\r\n",
      "0\t32\t3\t5\t\t1\t0\t0\t61\t5\t0\t1\t3157\t5\te5f3fd8d\ta0aaffa6\t6faa15d5\tda8a3421\t3cd69f23\t6fcd6dcb\tab16ed81\t43426c29\t1df5e154\t7de9c0a9\t6652dc64\t99eb4e27\t00c5ffb7\tbe4ee537\tf3bbfe99\t4cdc3efa\td20856aa\ta1eb1511\t9512c20b\tfebfd863\ta3323ca1\tc8e1ee56\t1752e9e8\t75350c8a\t991321ea\tb757e957\r\n"
     ]
    }
   ],
   "source": [
    "head -2 data/day_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a description of the dataset from the Criteo website:\n",
    "\n",
    "The columns are tab separated with the following schema:<br>\n",
    "&lt;label&gt; &lt;integer feature 1&gt; … &lt;integer feature 13&gt; &lt;categorical feature 1&gt; … &lt;categorical feature 26&gt;\n",
    "When a value is missing, the field is just empty.\n",
    "\n",
    "So the first field is the target value (a 1 when someone clicked on the ad, a 0 when the didn't).  Then we have numeric features, and a bunch of categorical features which we would normally need to expand out into dummies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using vowpal wabbit, which you can get from github [here](https://github.com/JohnLangford/vowpal_wabbit).  We'll be working with version 7.7, though I doubt the particular version is crucial.  Windows installation instructions here [here](https://github.com/JohnLangford/vowpal_wabbit/blob/master/README.windows.txt), though I've never tried to get it working on Windows, so YMMV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7.0\r\n"
     ]
    }
   ],
   "source": [
    "vw --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VW has a huge array of commandline options, which you can read about from the help menu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\r\n",
      "learning rate = 0.5\r\n",
      "initial_t = 0\r\n",
      "power_t = 0.5\r\n",
      "using no cache\r\n",
      "Reading datafile = \r\n",
      "num sources = 1\r\n",
      "\r\n",
      "\r\n",
      "VW options:\r\n",
      "  --random_seed arg               seed random number generator\r\n",
      "  --ring_size arg                 size of example ring\r\n",
      "\r\n",
      "Update options:\r\n",
      "  -l [ --learning_rate ] arg Set learning rate\r\n",
      "  --power_t arg              t power value\r\n",
      "  --decay_learning_rate arg  Set Decay factor for learning_rate between passes\r\n",
      "  --initial_t arg            initial t value\r\n",
      "  --feature_mask arg         Use existing regressor to determine which \r\n",
      "                             parameters may be updated.  If no \r\n",
      "                             initial_regressor given, also used for initial \r\n",
      "                             weights.\r\n",
      "\r\n",
      "Weight options:\r\n",
      "  -i [ --initial_regressor ] arg  Initial regressor(s)\r\n",
      "  --initial_weight arg            Set all weights to an initial value of 1.\r\n",
      "  --random_weights arg            make initial weights random\r\n",
      "  --input_feature_regularizer arg Per feature regularization input file\r\n",
      "\r\n",
      "Active Learning options:\r\n",
      "  --active_learning       active learning mode\r\n",
      "  --active_simulation     active learning simulation mode\r\n",
      "  --active_mellowness arg active learning mellowness parameter c_0. Default 8\r\n",
      "\r\n",
      "Parallelization options:\r\n",
      "  --span_server arg     Location of server for setting up spanning tree\r\n",
      "  --unique_id arg       unique id used for cluster parallel jobs\r\n",
      "  --total arg           total number of nodes used in cluster parallel job\r\n",
      "  --node arg            node number in cluster parallel job\r\n",
      "\r\n",
      "Other options:\r\n",
      "  -B [ --bootstrap ] arg bootstrap mode with k rounds by online importance \r\n",
      "                         resampling\r\n",
      "\r\n",
      "Diagnostic options:\r\n",
      "  --version             Version information\r\n",
      "  -a [ --audit ]        print weights of features\r\n",
      "  -P [ --progress ] arg Progress update frequency. int: additive, float: \r\n",
      "                        multiplicative\r\n",
      "  --quiet               Don't output disgnostics and progress updates\r\n",
      "  -h [ --help ]         Look here: http://hunch.net/~vw/ and click on Tutorial.\r\n",
      "\r\n",
      "Feature options:\r\n",
      "  --hash arg                 how to hash the features. Available options: \r\n",
      "                             strings, all\r\n",
      "  --ignore arg               ignore namespaces beginning with character <arg>\r\n",
      "  --keep arg                 keep namespaces beginning with character <arg>\r\n",
      "  -b [ --bit_precision ] arg number of bits in the feature table\r\n",
      "  --noconstant               Don't add a constant feature\r\n",
      "  -C [ --constant ] arg      Set initial value of constant\r\n",
      "  --ngram arg                Generate N grams. To generate N grams for a single\r\n",
      "                             namespace 'foo', arg should be fN.\r\n",
      "  --skips arg                Generate skips in N grams. This in conjunction \r\n",
      "                             with the ngram tag can be used to generate \r\n",
      "                             generalized n-skip-k-gram. To generate n-skips for\r\n",
      "                             a single namespace 'foo', arg should be fn.\r\n",
      "  --affix arg                generate prefixes/suffixes of features; argument \r\n",
      "                             '+2a,-3b,+1' means generate 2-char prefixes for \r\n",
      "                             namespace a, 3-char suffixes for b and 1 char \r\n",
      "                             prefixes for default namespace\r\n",
      "  --spelling arg             compute spelling features for a give namespace \r\n",
      "                             (use '_' for default namespace)\r\n",
      "  -q [ --quadratic ] arg     Create and use quadratic features\r\n",
      "  --q: arg                   : corresponds to a wildcard for all printable \r\n",
      "                             characters\r\n",
      "  --cubic arg                Create and use cubic features\r\n",
      "\r\n",
      "Example options:\r\n",
      "  -t [ --testonly ]              Ignore label information and just test\r\n",
      "  --holdout_off                  no holdout data in multiple passes\r\n",
      "  --holdout_period arg           holdout period for test only, default 10\r\n",
      "  --holdout_after arg            holdout after n training examples, default off\r\n",
      "                                 (disables holdout_period)\r\n",
      "  --early_terminate arg          Specify the number of passes tolerated when \r\n",
      "                                 holdout loss doesn't decrease before early \r\n",
      "                                 termination, default is 3\r\n",
      "  --passes arg                   Number of Training Passes\r\n",
      "  --initial_pass_length arg      initial number of examples per pass\r\n",
      "  --examples arg                 number of examples to parse\r\n",
      "  --min_prediction arg           Smallest prediction to output\r\n",
      "  --max_prediction arg           Largest prediction to output\r\n",
      "  --sort_features                turn this on to disregard order in which \r\n",
      "                                 features have been defined. This will lead to \r\n",
      "                                 smaller cache sizes\r\n",
      "  --loss_function arg (=squared) Specify the loss function to be used, uses \r\n",
      "                                 squared by default. Currently available ones \r\n",
      "                                 are squared, classic, hinge, logistic and \r\n",
      "                                 quantile.\r\n",
      "  --quantile_tau arg (=0.5)      Parameter \\tau associated with Quantile loss. \r\n",
      "                                 Defaults to 0.5\r\n",
      "  --l1 arg                       l_1 lambda\r\n",
      "  --l2 arg                       l_2 lambda\r\n",
      "\r\n",
      "base algorithms (these are exclusive):\r\n",
      "  --sgd                  use regular stochastic gradient descent update.\r\n",
      "  --adaptive             use adaptive, individual learning rates.\r\n",
      "  --invariant            use safe/importance aware updates.\r\n",
      "  --normalized           use per feature normalized updates\r\n",
      "  --exact_adaptive_norm  use current default invariant normalized adaptive \r\n",
      "                         update rule\r\n",
      "  --bfgs                 use bfgs optimization\r\n",
      "  --lda arg              Run lda with <int> topics\r\n",
      "  --rank arg             rank for matrix factorization.\r\n",
      "  --noop                 do no learning\r\n",
      "  --print                print examples\r\n",
      "  --sendto arg           send examples to <host>\r\n",
      "\r\n",
      "Output model:\r\n",
      "  -f [ --final_regressor ] arg          Final regressor\r\n",
      "  --readable_model arg                  Output human-readable final regressor \r\n",
      "                                        with numeric features\r\n",
      "  --invert_hash arg                     Output human-readable final regressor \r\n",
      "                                        with feature names.  Computationally \r\n",
      "                                        expensive.\r\n",
      "  --save_resume                         save extra state so learning can be \r\n",
      "                                        resumed later with new data\r\n",
      "  --save_per_pass                       Save the model after every pass over \r\n",
      "                                        data\r\n",
      "  --output_feature_regularizer_binary arg\r\n",
      "                                        Per feature regularization output file\r\n",
      "  --output_feature_regularizer_text arg Per feature regularization output file,\r\n",
      "                                        in text\r\n",
      "\r\n",
      "Output options:\r\n",
      "  -p [ --predictions ] arg     File to output predictions to\r\n",
      "  -r [ --raw_predictions ] arg File to output unnormalized predictions to\r\n",
      "\r\n",
      "Score modifying options (can be combined):\r\n",
      "  --nn arg              Use sigmoidal feedforward network with <k> hidden units\r\n",
      "  --new_mf              use new, reduction-based matrix factorization\r\n",
      "  --autolink arg        create link function with polynomial d\r\n",
      "  --lrq arg             use low rank quadratic features\r\n",
      "  --lrqdropout          use dropout training for low rank quadratic features\r\n",
      "  --stage_poly          use stagewise polynomial feature learning\r\n",
      "\r\n",
      "Score user options (these are exclusive):\r\n",
      "  --top arg             top k recommendation\r\n",
      "  --binary              report loss as binary classification on -1,1\r\n",
      "  --oaa arg             Use one-against-all multiclass learning with <k> labels\r\n",
      "  --ect arg             Use error correcting tournament with <k> labels\r\n",
      "  --log_multi arg       Use online tree for multiclass\r\n",
      "  --csoaa arg           Use one-against-all multiclass learning with <k> costs\r\n",
      "  --wap arg             Use weighted all-pairs multiclass learning with <k> \r\n",
      "                        costs\r\n",
      "  --csoaa_ldf arg       Use one-against-all multiclass learning with label \r\n",
      "                        dependent features.  Specify singleline or multiline.\r\n",
      "  --wap_ldf arg         Use weighted all-pairs multiclass learning with label \r\n",
      "                        dependent features.  Specify singleline or multiline.\r\n",
      "\r\n",
      "Contextual Bandit options:\r\n",
      "  --cb arg              Use contextual bandit learning with <k> costs\r\n",
      "  --cbify arg           Convert multiclass on <k> classes into a contextual \r\n",
      "                        bandit problem and solve\r\n",
      "\r\n",
      "Search:\r\n",
      "  --search arg          use search-based structured prediction, \r\n",
      "                        argument=maximum action id or 0 for LDF\r\n",
      "\r\n",
      "Input options:\r\n",
      "  -d [ --data ] arg     Example Set\r\n",
      "  --daemon              persistent daemon mode on port 26542\r\n",
      "  --port arg            port to listen on; use 0 to pick unused port\r\n",
      "  --num_children arg    number of children for persistent daemon mode\r\n",
      "  --pid_file arg        Write pid file in persistent daemon mode\r\n",
      "  --port_file arg       Write port used in persistent daemon mode\r\n",
      "  -c [ --cache ]        Use a cache.  The default is <data>.cache\r\n",
      "  --cache_file arg      The location(s) of cache_file.\r\n",
      "  -k [ --kill_cache ]   do not reuse existing cache: create a new one always\r\n",
      "  --compressed          use gzip format whenever possible. If a cache file is \r\n",
      "                        being created, this option creates a compressed cache \r\n",
      "                        file. A mixture of raw-text & compressed inputs are \r\n",
      "                        supported with autodetection.\r\n",
      "  --no_stdin            do not default to reading from stdin\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "vw --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we need to do is to convert the log file into the input format that VW expects.  VW comes with a utility called `vw-csv2bin`, but we're going to write some simple python code to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tsv_to_vw(tsv_file, vw_file, skip_lines, num_lines):\n",
    "    print \"\\nTurning %s into %s...\" % (tsv_file, vw_file)\n",
    "\n",
    "    # open our input file and an output file to write to\n",
    "    with open(tsv_file, 'r') as infile, open(vw_file, 'w') as outfile:        \n",
    "        lines_read=0\n",
    "        lines_skipped=0\n",
    "        # read the file line by line\n",
    "        for line in infile:\n",
    "            # we want to skip the first skip_lines lines of the file\n",
    "            if skip_lines!=0 and lines_skipped<skip_lines:\n",
    "                lines_skipped += 1\n",
    "                continue\n",
    "  \n",
    "            # if we've converted num_lines already, stop\n",
    "            if lines_read>= num_lines: return\n",
    "\n",
    "            # othewise, convert the line\n",
    "            out_line = \"\"\n",
    "            # get rid of the newline at the end of the line\n",
    "            line = re.sub('\\n', '', line)\n",
    "            # split the file on tabs\n",
    "            data = re.split('\\t', line)\n",
    "\n",
    "            # pop off our target/label column and write the label | for vw\n",
    "            target = data.pop(0)        \n",
    "            out_line += \"1 | \" if target == \"1\" else \"-1 | \"\n",
    "\n",
    "            # write the 13 integer features in a form like feature:val, e.g. f0:124\n",
    "            for i in range(13):\n",
    "                out_line += \"f%s:\" % i\n",
    "                if data[i] == \"\":\n",
    "                    out_line += \"0 \"\n",
    "                else:\n",
    "                    out_line += \"%s \" % data[i]\n",
    "\n",
    "            # all the rest are the categorical features, so we just write these directly\n",
    "            # and vw will interpet them as F:1 when they're present, F:0 when they're not\n",
    "            for i in range(13, len(data)):\n",
    "                if data[i] == \"\": continue\n",
    "                out_line += \"f%s_%s \" % (i, data[i])\n",
    "\n",
    "            out_line += \"\\n\"\n",
    "            outfile.write(out_line)\n",
    "            lines_read += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DON'T RE-RUN THIS, BECAUSE IT WILL TAKE FOREVER...\n",
    "# also, only write out 2mm lines because my hard drive fills up...\n",
    "tsv_to_vw(\"data/day_0\", \"data/day_0.vw\", skip_lines=0, num_lines=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsv_to_vw(\"data/day_0\", \"data/day_0.test.vw\", skip_lines=2000000, num_lines=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | f0:5 f1:110 f2:0 f3:16 f4:0 f5:1 f6:0 f7:14 f8:7 f9:1 f10:0 f11:306 f12:0 f13_62770d79 f14_e21f5d58 f15_afea442f f16_945c7fcf f17_38b02748 f18_6fcd6dcb f19_3580aa21 f20_28808903 f21_46dedfa6 f22_2e027dc1 f23_0c7c4231 f24_95981d1f f25_00c5ffb7 f26_be4ee537 f27_8a0b74cc f28_4cdc3efa f29_d20856aa f30_b8170bba f31_9512c20b f32_c38e2f28 f33_14f65a5d f34_25b1b089 f35_d7c1fc0b f36_7caf609c f37_30436bfc f38_ed10571d \r\n",
      "-1 | f0:32 f1:3 f2:5 f3:0 f4:1 f5:0 f6:0 f7:61 f8:5 f9:0 f10:1 f11:3157 f12:5 f13_e5f3fd8d f14_a0aaffa6 f15_6faa15d5 f16_da8a3421 f17_3cd69f23 f18_6fcd6dcb f19_ab16ed81 f20_43426c29 f21_1df5e154 f22_7de9c0a9 f23_6652dc64 f24_99eb4e27 f25_00c5ffb7 f26_be4ee537 f27_f3bbfe99 f28_4cdc3efa f29_d20856aa f30_a1eb1511 f31_9512c20b f32_febfd863 f33_a3323ca1 f34_c8e1ee56 f35_1752e9e8 f36_75350c8a f37_991321ea f38_b757e957 \r\n",
      "-1 | f0:0 f1:233 f2:1 f3:146 f4:1 f5:0 f6:0 f7:99 f8:7 f9:0 f10:1 f11:3101 f12:1 f13_62770d79 f14_ad984203 f15_62bec60d f16_386c49ee f17_e755064d f18_6fcd6dcb f19_b5f5eb62 f20_d1f2cc8b f21_2e4e821f f22_2e027dc1 f23_0c7c4231 f24_12716184 f25_00c5ffb7 f26_be4ee537 f27_f70f0d0b f28_4cdc3efa f29_d20856aa f30_628f1b8d f31_9512c20b f32_c38e2f28 f33_14f65a5d f34_25b1b089 f35_d7c1fc0b f36_34a9b905 f37_ff654802 f38_ed10571d \r\n",
      "-1 | f0:0 f1:24 f2:0 f3:11 f4:24 f5:0 f6:0 f7:56 f8:3 f9:0 f10:2 f11:20456 f12:0 f14_710103fd f15_c73d2eb5 f16_0c758dfb f17_f1738f48 f18_6fcd6dcb f19_e824fc11 f20_09f8a09d f21_e25a4c11 f24_12716184 f25_d49eb1df f26_b96f9e1a f27_2b083b96 f28_10dd3744 f29_1f7fc70b f30_a1eb1511 f31_9512c20b f35_dc209cd3 f36_b8a81fb0 f37_30436bfc f38_b757e957 \r\n",
      "-1 | f0:60 f1:223 f2:6 f3:15 f4:5 f5:0 f6:0 f7:1 f8:8 f9:0 f10:2 f11:1582 f12:6 f13_02e197c5 f14_c2ced437 f15_a2427619 f16_3f85ecae f17_b8c51ab7 f18_6fcd6dcb f19_26d0f5bb f20_337bf7a5 f21_e25a4c11 f22_6da2367e f23_bf624fa3 f24_ec982ce0 f25_a77a4a56 f26_be4ee537 f27_eb24f585 f28_4cdc3efa f29_d20856aa f30_d9f758ff f31_9512c20b f32_c709ec07 f33_2b07677e f34_a89a92a5 f35_aa137169 f36_e619743b f37_cdc3217e f38_ed10571d \r\n",
      "1 | f0:7 f1:1 f2:10 f3:2 f4:0 f5:3 f6:0 f7:0 f8:12 f9:1 f10:0 f11:4 f12:2 f13_8a2b1e43 f14_3fa554c6 f15_0b8e4616 f16_f2463ffb f17_c6fc10d3 f18_6fcd6dcb f19_ca33cfe1 f20_ec70a584 f21_1df5e154 f22_31184e3d f23_fa478aa9 f24_ea19984d f25_bf78d0d4 f27_1db5813f f30_b8170bba f31_9512c20b f32_8024f45f f33_0683bc6f f34_fa7eca6c f36_ecfbb046 f37_ff654802 f38_b757e957 \r\n",
      "-1 | f0:1 f1:52 f2:1 f3:59 f4:9 f5:0 f6:0 f7:1 f8:1 f9:0 f10:2 f11:40969 f12:1 f13_a80f39e1 f14_79782afd f15_ddb2d2e1 f16_3f85ecae f17_27d2607e f18_6fcd6dcb f19_3c024557 f20_3e03ba26 f21_25dd8f9a f22_e6c4de5e f23_a5c09e1f f24_9a1f0c1e f25_a77a4a56 f27_fbc36ae9 f30_6691e292 f31_9512c20b f32_0c973540 f33_1443a006 f34_5f0a75ba f36_ae2a9011 f37_321935cd f38_74a20f02 \r\n",
      "-1 | f0:81 f1:394 f2:5 f3:0 f4:8 f5:0 f6:0 f7:11 f8:10 f9:0 f10:1 f11:30814 f12:5 f13_a46c5216 f14_ddc72fb0 f15_49c7ebf8 f16_386c49ee f17_6c49ffa1 f18_919c68e4 f19_407011ef f20_b2a2bd17 f21_2e4e821f f22_bd939915 f23_62891297 f24_12716184 f25_d49eb1df f26_be4ee537 f27_57469cbd f28_4cdc3efa f29_753da5f3 f30_d9fd9ab1 f31_9512c20b f32_3904f3e1 f33_9d4a8e96 f34_87cdacc3 f35_c41c9ca8 f36_bf38b85a f37_30436bfc f38_ed10571d \r\n",
      "-1 | f0:1 f1:3 f2:0 f3:0 f4:0 f5:0 f6:0 f7:1748 f8:5 f9:0 f10:0 f11:2285 f12:1 f13_9318c40b f14_53c06361 f15_fea787e5 f16_d9a8ea57 f17_58f5b2da f18_6fcd6dcb f19_85b703eb f20_586d6aed f21_2e4e821f f22_5a26a4e7 f23_750506a2 f24_e07b0a69 f25_405ca118 f26_be4ee537 f27_4354aec1 f28_4cdc3efa f29_d20856aa f30_b8170bba f31_9512c20b f32_4417662d f33_5731c43e f34_ad2dfc1d f35_a3d67fd4 f36_a8141335 f37_30436bfc f38_ed10571d \r\n",
      "-1 | f0:4 f1:20 f2:3 f3:7 f4:1 f5:1 f6:1 f7:8 f8:9 f9:1 f10:1 f11:53 f12:3 f13_62770d79 f14_ad984203 f15_ddd956c1 f16_f7f54f97 f17_bbaea1c0 f18_6fcd6dcb f19_3dfbcac0 f20_d1f2cc8b f21_2e4e821f f22_2e027dc1 f23_0c7c4231 f24_12716184 f25_f4fc3c5e f26_be4ee537 f27_f70f0d0b f28_4cdc3efa f29_d20856aa f30_b8170bba f31_9512c20b f32_c38e2f28 f33_14f65a5d f34_25b1b089 f35_d7c1fc0b f36_90b2fb17 f37_30436bfc f38_ed10571d \r\n"
     ]
    }
   ],
   "source": [
    "head -10 data/day_0.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can validate the format with the super useful [VW format validator tool](http://hunch.net/~vw/validate.html\n",
    ")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll train a logistic regression model.  The `-f` flag tells it where to store the final model, and the `-d` option is for the input data.  (Note, this provides realtime feedback in the terminal that you can't see in the notebook...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw --loss_function logistic -f data/day_0.model -d data/day_0.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of displaying the logistic loss function values, we can have it display the binary accuracy instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw --loss_function logistic --binary -f data/day_0.model -d data/day_0.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is 94% 0's, so getting an accuracy of 97% means that it is indeed learning something about the 1's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have VW make multiple passes over the data.  In general, the more passes the better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw --loss_function logistic --binary -f data/day_0.model -d data/day_0.vw -c --passes 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can apply the model to new data with the `-t` flag.  Predictions will be written to the file specified by the `-p` flag and raw predictions to the file specified by the `-r` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw -t --binary -i data/day_0.model -d data/day_0.test.vw -p data/day_0.test.preds -r data/day_0.test.raw.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head -10 data/day_0.test.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head -10 data/day_0.test.raw.preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a file with only the true test predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut -d \"|\" -f 1 data/day_0.test.vw > data/day_0.test.true.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head -10 data/day_0.test.true.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0     -1\n",
       "1     -1\n",
       "2     -1\n",
       "3     -1\n",
       "4     -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"data/day_0.test.true.labels\", header=None)\n",
    "labels.columns = [\"label\"]\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.131194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.305913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.647429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.926275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.201283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred\n",
       "0 -6.131194\n",
       "1 -4.305913\n",
       "2 -5.647429\n",
       "3 -2.926275\n",
       "4 -4.201283"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.read_csv(\"data/day_0.test.raw.preds\", header=None)\n",
    "preds.columns = [\"pred\"]\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFVCAYAAADVDycqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b254250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(labels.label, preds.pred)\n",
    "fpr_rand = tpr_rand = np.linspace(0, 1, 10)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot(fpr_rand, tpr_rand, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71823137507417334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(labels.label, preds.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell VW to generate all quadratic interaction features and use them in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-8469a05caee3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-8469a05caee3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    vw --loss_function logistic --binary -q aa -b 24 -d data/day_0.vw\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "vw --loss_function logistic --binary -q aa -b 24 -d data/day_0.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with cubic features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw --loss_function logistic --binary --cubic aaa -d data/day_0.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add lasso or ridge penalties to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw --loss_function logistic --binary --l1 0.1 -d data/day_0.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw --loss_function logistic --binary --l2 0.1 -d data/day_0.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had defined feature namespaces, we can mask entire chunks of features in and out of the model with the `--ignore` and `--keep` options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get an idea of feature importances with the `vw-varinfo` script.  Let's first generate a tiny version of our training dataset so that this will go quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head -1000 data/day_0.vw > data/day_0.small.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw-varinfo -d data/day_0.small.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also train a support vector machine by using the \"hinge\" loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw --loss_function hinge --binary -f data/day_0.model -d data/day_0.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
