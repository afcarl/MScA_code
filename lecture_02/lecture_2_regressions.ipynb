{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Linear Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll see examples of how to use the scikit-learn linear regression class, as well as the statsmodels OLS function, which is much more similar to R's lm function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a random dataset where X is uniformly distributed between 0 and 1, and y is a consine function plus noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "noise_size = 0.1\n",
    "y = true_fun(X) + np.random.randn(n_samples) * noise_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10d188450>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAFVCAYAAAAt79zdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c127e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn linear regression class has the same programming interface we saw with k-NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X.reshape((30, 1)), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the parameters of the fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536680330318\n",
      "[-1.60931179]\n"
     ]
    }
   ],
   "source": [
    "print linear_regression.intercept_\n",
    "print linear_regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can print the predictions as a line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (100,1) and (2,) not aligned: 1 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cb48b363ebc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_to_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_to_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mdagostino/.virtualenvs/jupyter/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0m_center_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mdagostino/.virtualenvs/jupyter/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 140\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mdagostino/.virtualenvs/jupyter/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (100,1) and (2,) not aligned: 1 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "# equally spaced array of 100 values between 0 and 1, like the seq function in R\n",
    "X_to_pred = np.linspace(0, 1, 100).reshape(100, 1)\n",
    "\n",
    "preds = linear_regression.predict(X_to_pred)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X_to_pred, preds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a model of the form $y \\sim x + x^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.08783595e-04,   5.04612156e-03,   7.59151487e-03,\n",
       "         1.39888398e-02,   2.05501650e-02,   1.47027398e-01,\n",
       "         1.71944524e-01,   1.79483389e-01,   1.91482567e-01,\n",
       "         2.12963202e-01,   2.72325671e-01,   2.79729836e-01,\n",
       "         2.96897683e-01,   3.01196262e-01,   3.22674623e-01,\n",
       "         3.63323688e-01,   4.09498914e-01,   4.17179205e-01,\n",
       "         5.11495830e-01,   6.05527929e-01,   6.09225795e-01,\n",
       "         6.26828536e-01,   6.38654411e-01,   6.93255807e-01,\n",
       "         7.56921138e-01,   7.95259085e-01,   8.56729137e-01,\n",
       "         8.92399363e-01,   9.28645916e-01,   9.57693860e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.02183974e-02,   4.08783595e-04],\n",
       "       [  7.10360582e-02,   5.04612156e-03],\n",
       "       [  8.71292997e-02,   7.59151487e-03],\n",
       "       [  1.18274426e-01,   1.39888398e-02],\n",
       "       [  1.43353287e-01,   2.05501650e-02],\n",
       "       [  3.83441519e-01,   1.47027398e-01],\n",
       "       [  4.14661940e-01,   1.71944524e-01],\n",
       "       [  4.23654799e-01,   1.79483389e-01],\n",
       "       [  4.37587211e-01,   1.91482567e-01],\n",
       "       [  4.61479362e-01,   2.12963202e-01],\n",
       "       [  5.21848322e-01,   2.72325671e-01],\n",
       "       [  5.28894920e-01,   2.79729836e-01],\n",
       "       [  5.44883183e-01,   2.96897683e-01],\n",
       "       [  5.48813504e-01,   3.01196262e-01],\n",
       "       [  5.68044561e-01,   3.22674623e-01],\n",
       "       [  6.02763376e-01,   3.63323688e-01],\n",
       "       [  6.39921021e-01,   4.09498914e-01],\n",
       "       [  6.45894113e-01,   4.17179205e-01],\n",
       "       [  7.15189366e-01,   5.11495830e-01],\n",
       "       [  7.78156751e-01,   6.05527929e-01],\n",
       "       [  7.80529176e-01,   6.09225795e-01],\n",
       "       [  7.91725038e-01,   6.26828536e-01],\n",
       "       [  7.99158564e-01,   6.38654411e-01],\n",
       "       [  8.32619846e-01,   6.93255807e-01],\n",
       "       [  8.70012148e-01,   7.56921138e-01],\n",
       "       [  8.91773001e-01,   7.95259085e-01],\n",
       "       [  9.25596638e-01,   8.56729137e-01],\n",
       "       [  9.44668917e-01,   8.92399363e-01],\n",
       "       [  9.63662761e-01,   9.28645916e-01],\n",
       "       [  9.78618342e-01,   9.57693860e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.column_stack((X, X**2))\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54114868724\n",
      "[-7.31956683  5.55955392]\n"
     ]
    }
   ],
   "source": [
    "print linear_regression.intercept_\n",
    "print linear_regression.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAFVCAYAAAAt79zdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBv4/xjFNjtUrZj4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d42d750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# equally spaced array of 100 values between 0 and 1, like the seq function in R\n",
    "X_p = np.linspace(0, 1, 100).reshape(100, 1)\n",
    "X_to_pred = np.column_stack((X_p, X_p**2))\n",
    "\n",
    "preds = linear_regression.predict(X_to_pred)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X_p, preds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `statsmodels` package provides statistical functionality a lot like R's for doing OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/ols.html](http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/ols.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "np.random.seed(9876789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using A Formula to Fit to a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://statsmodels.sourceforge.net/0.6.0/examples/notebooks/generated/formulas.html](http://statsmodels.sourceforge.net/0.6.0/examples/notebooks/generated/formulas.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dta = sm.datasets.get_rdataset(\"Guerry\", \"HistData\", cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lottery</th>\n",
       "      <th>Literacy</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>73</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>22</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>61</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>46</td>\n",
       "      <td>76</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>84</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>81</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>86</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>72</td>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>77</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>31</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>54</td>\n",
       "      <td>42</td>\n",
       "      <td>66</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "      <td>51</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>79</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>71</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>46</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>71</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>67</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>64</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>56</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>82</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>83</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Lottery  Literacy  Wealth Region\n",
       "0        41        37      73      E\n",
       "1        38        51      22      N\n",
       "2        66        13      61      C\n",
       "3        80        46      76      E\n",
       "4        79        69      83      E\n",
       "5        70        27      84      S\n",
       "6        31        67      33      N\n",
       "7        75        18      72      S\n",
       "8        28        59      14      E\n",
       "9        50        34      17      S\n",
       "10       81        31      50      S\n",
       "11        3        38       2      S\n",
       "12       13        52      10      N\n",
       "13       82        31      59      C\n",
       "14       60        36      86      W\n",
       "15       35        39      18      W\n",
       "16       44        13      63      C\n",
       "17       84        12      74      C\n",
       "18       33        60      16      E\n",
       "19       72        16      70      W\n",
       "20       85        23      78      C\n",
       "21       77        18      60      W\n",
       "22       18        73      31      E\n",
       "23       54        42      66      E\n",
       "24       47        51      20      N\n",
       "25       48        54      11      C\n",
       "26       36        15      36      W\n",
       "27       20        40      26      S\n",
       "28       25        31      23      S\n",
       "29       74        38      40      S\n",
       "..      ...       ...     ...    ...\n",
       "56        7        45      28      N\n",
       "57       43        54      15      N\n",
       "58       57        45      35      N\n",
       "59       27        49      45      N\n",
       "60       53        19      51      C\n",
       "61       34        47      79      W\n",
       "62       76        53      85      S\n",
       "63       11        31      71      S\n",
       "64        5        62      46      E\n",
       "65       10        71      58      E\n",
       "66        2        45       6      E\n",
       "67       65        59      69      E\n",
       "68       45        32      49      E\n",
       "69       49        30      41      C\n",
       "70        1        71       1      N\n",
       "71        9        43       3      N\n",
       "72       29        54       4      N\n",
       "73        6        56       5      N\n",
       "74       71        41      39      W\n",
       "75       30        44      21      N\n",
       "76       67        20      47      S\n",
       "77       64        25      29      S\n",
       "78       26        23      43      S\n",
       "79        8        37      64      S\n",
       "80       68        28      56      W\n",
       "81       40        25      68      W\n",
       "82       55        13      67      C\n",
       "83       14        62      82      E\n",
       "84       51        47      30      C\n",
       "85       83        49      37    NaN\n",
       "\n",
       "[86 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = dta.data\n",
    "original_df.head()\n",
    "subsetted_df = original_df[['Lottery', 'Literacy', 'Wealth', 'Region']]\n",
    "subsetted_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lottery</th>\n",
       "      <th>Literacy</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>73</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>22</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>61</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>46</td>\n",
       "      <td>76</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lottery  Literacy  Wealth Region\n",
       "0       41        37      73      E\n",
       "1       38        51      22      N\n",
       "2       66        13      61      C\n",
       "3       80        46      76      E\n",
       "4       79        69      83      E"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dta.data[['Lottery', 'Literacy', 'Wealth', 'Region']].dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Lottery   R-squared:                       0.338\n",
      "Model:                            OLS   Adj. R-squared:                  0.278\n",
      "Method:                 Least Squares   F-statistic:                     5.615\n",
      "Date:                Wed, 07 Oct 2015   Prob (F-statistic):           2.96e-05\n",
      "Time:                        20:22:25   Log-Likelihood:                -375.30\n",
      "No. Observations:                  85   AIC:                             766.6\n",
      "Df Residuals:                      77   BIC:                             786.1\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          39.0993     17.470      2.238      0.028         4.312    73.887\n",
      "Region[T.E]       -15.4451      9.807     -1.575      0.119       -34.973     4.082\n",
      "Region[T.N]        -9.9728      9.432     -1.057      0.294       -28.753     8.808\n",
      "Region[T.S]        -4.5754      7.380     -0.620      0.537       -19.270    10.119\n",
      "Region[T.W]       -10.1122      7.275     -1.390      0.169       -24.598     4.374\n",
      "Literacy           -0.1960      0.396     -0.495      0.622        -0.984     0.592\n",
      "Wealth              0.4432      0.290      1.530      0.130        -0.133     1.020\n",
      "Literacy:Wealth     0.0002      0.007      0.031      0.976        -0.013     0.013\n",
      "==============================================================================\n",
      "Omnibus:                        3.076   Durbin-Watson:                   1.784\n",
      "Prob(Omnibus):                  0.215   Jarque-Bera (JB):                2.709\n",
      "Skew:                          -0.341   Prob(JB):                        0.258\n",
      "Kurtosis:                       2.452   Cond. No.                     1.56e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.56e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula='Lottery ~ Literacy + Wealth + Region + Literacy:Wealth', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Lottery   R-squared:                       0.374\n",
      "Model:                            OLS   Adj. R-squared:                  0.299\n",
      "Method:                 Least Squares   F-statistic:                     4.988\n",
      "Date:                Wed, 07 Oct 2015   Prob (F-statistic):           2.92e-05\n",
      "Time:                        20:24:41   Log-Likelihood:                -372.89\n",
      "No. Observations:                  85   AIC:                             765.8\n",
      "Df Residuals:                      75   BIC:                             790.2\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           12.0464     22.334      0.539      0.591       -32.445    56.537\n",
      "Region[T.E]        -13.0916      9.839     -1.331      0.187       -32.692     6.508\n",
      "Region[T.N]         -9.5326      9.349     -1.020      0.311       -28.156     9.091\n",
      "Region[T.S]         -4.4507      7.297     -0.610      0.544       -18.987    10.085\n",
      "Region[T.W]         -9.6885      7.208     -1.344      0.183       -24.048     4.671\n",
      "Literacy            -0.0045      0.415     -0.011      0.991        -0.831     0.822\n",
      "Wealth               2.6587      1.100      2.416      0.018         0.467     4.851\n",
      "I(Wealth ** 2.0)    -0.0511      0.026     -1.955      0.054        -0.103     0.001\n",
      "I(Wealth ** 3.0)     0.0004      0.000      1.803      0.075     -3.73e-05     0.001\n",
      "Literacy:Wealth     -0.0043      0.007     -0.624      0.535        -0.018     0.009\n",
      "==============================================================================\n",
      "Omnibus:                        2.198   Durbin-Watson:                   1.808\n",
      "Prob(Omnibus):                  0.333   Jarque-Bera (JB):                2.106\n",
      "Skew:                          -0.309   Prob(JB):                        0.349\n",
      "Kurtosis:                       2.538   Cond. No.                     2.47e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.47e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula='Lottery ~ Literacy + Wealth + I(Wealth ** 2.0) + I(Wealth ** 3.0) + Region + Literacy:Wealth', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it were an integer code instead of a string, we could explicitly make `Region` categorical like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept         38.651655\n",
      "C(Region)[T.E]   -15.427785\n",
      "C(Region)[T.N]   -10.016961\n",
      "C(Region)[T.S]    -4.548257\n",
      "C(Region)[T.W]   -10.091276\n",
      "Literacy          -0.185819\n",
      "Wealth             0.451475\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "res = smf.ols(formula='Lottery ~ Literacy + Wealth + C(Region)', data=df).fit()\n",
    "print(res.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using numpy matrices directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a dataset which is $y \\sim 1+0.1x+10x^2+N(0,1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nsample = 500\n",
    "\n",
    "x = np.linspace(0, 10, 500)\n",
    "X = np.column_stack((x, x**2))\n",
    "\n",
    "beta = np.array([1, 0.1, 10])\n",
    "e = np.random.normal(size=nsample)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "y = np.dot(X, beta) + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the fit parameters like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Parameters: ', results.params\n",
    "print 'Standard errors: ', results.bse\n",
    "print 'Predicted values: ', results.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see an example with a categorical value with several levels, and how to expand it to dummies like the R lm function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nsample = 50\n",
    "\n",
    "# make an array that is all zeroes\n",
    "groups = np.zeros(nsample, int)\n",
    "# make some of the values 1's\n",
    "groups[20:40] = 1\n",
    "# and make some of them 2's\n",
    "groups[40:] = 2\n",
    "\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# have statsmodels expand the categorical variable into dummies\n",
    "dummy = sm.categorical(groups, drop=True)\n",
    "dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a dataset which is $y \\sim 0.1+3x-3group_1+10group_2+N(0,1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 20, nsample)\n",
    "# drop reference category\n",
    "X = np.column_stack((x, dummy[:,1:]))\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "beta = [1., 3, -3, 10]\n",
    "y_true = np.dot(X, beta)\n",
    "e = np.random.normal(size=nsample)\n",
    "y = y_true + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res2 = sm.OLS(y, X).fit()\n",
    "print res2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
